{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Self-Consistent gap equation\n",
        "$$\\Delta = \\lambda  \\int_{-Ec}^{Ec} \\Delta \\frac{tanh(\\frac {\\sqrt{\\xi^2 + |\\Delta|^2}}{2K_{b}T})}{2\\sqrt{\\xi^2 + |\\Delta|^2}}d\\xi $$"
      ],
      "metadata": {
        "id": "4FbaOQhg0wsF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oStxyWTb0v7R"
      },
      "outputs": [],
      "source": [
        "#Including libraries\n",
        "import numpy as np\n",
        "from scipy.integrate import quad\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "#Data generation\n",
        "def f(E):\n",
        "  return (lam*delta_in*np.tanh(np.sqrt(E**2 + abs(delta_in)**2)/(2*Kb*T)))/(2*np.sqrt((E**2 + abs(delta_in)**2)))\n",
        "\n",
        "import timeit\n",
        "time_list = []\n",
        "\n",
        "import numpy as np\n",
        "from pandas.core.sorting import lexsort_indexer\n",
        "import pandas as pd\n",
        "#physical parameters of the function\n",
        "lam_vetor = np.linspace(0.01, 1, 20)\n",
        "T_vetor = np.linspace(0,90, 100)\n",
        "Ec_vetor = np.linspace(100,10000,10)\n",
        "Kb = k\n",
        "data_frame = pd.DataFrame()\n",
        "c = 0\n",
        "array_simple = [[]] #T, lam, Ec, initial, convergence_value\n",
        "#data generation loop with parameters\n",
        "for Ec in Ec_vetor:\n",
        "  for lam in lam_vetor:\n",
        "    for T in T_vetor:\n",
        "      i=0\n",
        "      c+=1\n",
        "      #bruce force method\n",
        "      delta_in = 10\n",
        "      start = timeit.default_timer()#time\n",
        "      delta_fin = quad(f, -Ec, Ec)\n",
        "      delta_in_list = [delta_in]\n",
        "      while (abs(delta_in- delta_fin[0])>1e-4):\n",
        "        delta_in = delta_fin[0]\n",
        "        delta_fin = quad(f, -Ec, Ec)\n",
        "        delta_in_list.append(delta_in)\n",
        "        i += 1\n",
        "      #time\n",
        "      stop = timeit.default_timer()\n",
        "      time_list.append(stop-start)\n",
        "      if delta_in_list[-1]>1e-2:#excluding the trivial solution\n",
        "        array_simple.append([T, lam, Ec, delta_in_list[0], delta_in_list[-1]])\n",
        "        delta_in_list = np.array(delta_in_list).reshape(-1,1)\n",
        "        iterations = np.array(range(i+1)).reshape(-1,1)\n",
        "        final = np.concatenate((iterations,delta_in_list), axis = 1)\n",
        "        final = pd.DataFrame(final)\n",
        "        data_frame = pd.concat([data_frame, final], axis=1)\n",
        "\n",
        "print('Time: ', sum(time_list))  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "\n",
        "array_simple = pd.read_csv('data (1).csv')\n",
        "array_simple = pd.DataFrame(array_simple)\n",
        "array_simple.dropna(inplace = True)\n",
        "print(array_simple)\n",
        "Y = array_simple.iloc[:,4]\n",
        "X = array_simple.iloc[:,0:3]\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.4, random_state = 42)#40% for train\n",
        "\n",
        "#Scaling Data\n",
        "scaler = StandardScaler()\n",
        "scaled_X_train = scaler.fit_transform(X_train)\n",
        "scaled_X_test = scaler.fit_transform(X_test)\n",
        "\n",
        "#Hyperparameters tuning\n",
        "n_estimators = [2,3,4,5,6,7,8,9, 20,50,100] # number of trees\n",
        "max_features = ['auto', 'sqrt'] # max number of features for each split\n",
        "max_depth = [int(x) for x in np.linspace(4, 30, num = 1)] #length for each tree\n",
        "min_samples_split = [2, 4, 6,8, 10] # min number of features for each split\n",
        "min_samples_leaf = [1, 2,3, 4] # min number of samples leaf\n",
        "bootstrap = [True, False] \n",
        "\n",
        "#grid to search the best parameters\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "\n",
        "'max_features': max_features,\n",
        "\n",
        "'max_depth': max_depth,\n",
        "\n",
        "'min_samples_split': min_samples_split,\n",
        "\n",
        "'min_samples_leaf': min_samples_leaf,\n",
        "\n",
        "'bootstrap': bootstrap,}\n",
        "\n",
        "\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "rf_random = RandomizedSearchCV(estimator = rf,param_distributions = random_grid,\n",
        "               n_iter = 100, cv = 5, verbose=2, random_state=35, n_jobs = -1)\n",
        "\n",
        "rf_random.fit(X_train, Y_train)\n",
        "\n",
        "print ('Random grid: ', random_grid, '\\n')\n",
        "# print the best parameters\n",
        "print ('Best Parameters: ', rf_random.best_params_, ' \\n')\n",
        "\n",
        "#using the best model\n",
        "randmf = RandomForestRegressor(n_estimators =50, min_samples_leaf=4, min_samples_split = 2,  max_features = 'auto', max_depth= 5, bootstrap=True)  \n",
        "randmf.fit( X_train, Y_train) \n",
        "\n",
        "import timeit\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "start = timeit.default_timer()\n",
        "\n",
        "pred_i=randmf.predict( X_test) \n",
        "stop = timeit.default_timer()\n",
        "\n",
        "print('Time: ', stop - start)  \n",
        "print('time per test: ', (stop - start)/X_test.shape[0])\n",
        "\n",
        "mean_absolute_percentage_error(Y_test, pred_i)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(Y_test, pred_i)\n",
        "rmse = np.sqrt(mse)\n",
        "print(rmse) \n",
        "from sklearn.metrics import r2_score\n",
        "r2_score(Y_test, pred_i)\n",
        "y_train_predict = randmf.predict(X_train) \n",
        "print(r2_score(Y_test, pred_i), r2_score(Y_train, y_train_predict))\n",
        "\n",
        "plt.scatter(Y_test, pred_i, marker=3)\n",
        "plt.plot(Y_test, Y_test, color ='r')\n",
        "plt.ylabel('predicted')\n",
        "plt.xlabel('Y_real')\n",
        "plt.show()\n",
        "\n",
        "from sklearn.model_selection import cross_val_score,KFold\n",
        "\n",
        "kf=KFold(n_splits=5)\n",
        "score_train=cross_val_score(randmf,X_train,Y_train,cv=kf)\n",
        "#cross validation\n",
        "from sklearn.model_selection import cross_val_score,KFold\n",
        "kf=KFold(n_splits=5)\n",
        "score_test=cross_val_score(randmf,X_test,Y_test,cv=kf)\n",
        "\n",
        "plt.plot(score_train, label = 'treino')\n",
        "plt.plot(score_test, label = 'teste')\n",
        "plt.title('Cross Validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwclO0w41KhD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
